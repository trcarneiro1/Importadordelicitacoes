# üöÄ Guia R√°pido - Demonstra√ß√£o para Cliente

## Setup em 5 Minutos

### 1Ô∏è‚É£ Instalar Depend√™ncias
```bash
npm install
```

### 2Ô∏è‚É£ Configurar Supabase

**Criar Projeto:**
1. Acesse https://supabase.com e crie uma conta gratuita
2. Clique em "New Project"
3. Preencha: Nome, Database Password, Region (escolha South America)
4. Aguarde 2 minutos para projeto ser criado

**Copiar Credenciais:**
1. No projeto criado, v√° em Settings > API
2. Copie:
   - `Project URL`
   - `anon public` (chave p√∫blica)
   - `service_role` (chave de servi√ßo - clicar em "Reveal")

**Configurar .env.local:**
1. Copie o arquivo `.env.local.example` para `.env.local`
2. Cole as 3 credenciais copiadas:

```env
NEXT_PUBLIC_SUPABASE_URL=https://xxxxxxxx.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...
SUPABASE_SERVICE_ROLE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...
```

### 3Ô∏è‚É£ Criar Tabelas no Banco

1. No Supabase, clique em **SQL Editor** (menu lateral)
2. Clique em **+ New Query**
3. Abra o arquivo `lib/supabase/schema.sql` deste projeto
4. Copie TODO o conte√∫do
5. Cole no SQL Editor do Supabase
6. Clique em **Run** (Ctrl+Enter)
7. Confirme sucesso: "Success. No rows returned"

### 4Ô∏è‚É£ Iniciar Aplica√ß√£o

```bash
npm run dev
```

Abra no navegador: http://localhost:3000

## üé¨ Roteiro de Demonstra√ß√£o

### Passo 1: P√°gina Inicial
- Mostre a homepage explicando o conceito
- 47 SREs monitoradas
- 2 funcionalidades principais: Dashboard e Coleta

### Passo 2: Executar Coleta
1. Clique em "Coletar Dados"
2. Deixe o padr√£o: 1 SRE
3. Clique em "Iniciar Coleta"
4. Aguarde ~5-10 segundos
5. Mostre os resultados:
   - Status de sucesso/erro
   - N√∫mero de registros encontrados

### Passo 3: Visualizar Dashboard
1. Clique em "Ver Dashboard"
2. Mostre:
   - Estat√≠sticas (Total, SREs com dados, √öltimas 24h)
   - Tabela com licita√ß√µes coletadas
3. Clique em "Atualizar" para refresh

### Passo 4: Testar API (Opcional)

Abra um novo terminal e teste:

```bash
# Listar licita√ß√µes coletadas
curl http://localhost:3000/api/licitacoes

# Ver logs de execu√ß√£o
curl http://localhost:3000/api/logs

# Coletar mais 2 SREs
curl http://localhost:3000/api/scrape?count=2
```

## üí° Pontos-Chave para Destacar

### ‚úÖ Viabilidade T√©cnica Comprovada
"Este POC demonstra que √© tecnicamente vi√°vel coletar dados de licita√ß√µes dos 47 portais SRE de forma automatizada."

### ‚úÖ Escalabilidade
"A arquitetura escolhida (Next.js + Supabase) permite crescimento sem grandes refatora√ß√µes. Podemos escalar para milhares de coletas di√°rias."

### ‚úÖ Flexibilidade
"Sistema preparado para integra√ß√£o via API REST. Qualquer aplica√ß√£o pode consumir os dados coletados."

### ‚úÖ Custo-Benef√≠cio
"Stack completamente gratuita no in√≠cio:
- Supabase: 500MB storage, 2GB transfer/m√™s (gr√°tis)
- Vercel: Deploy ilimitado (gr√°tis)
- Custo estimado inicial: R$ 0/m√™s"

## ‚ö†Ô∏è Limita√ß√µes Explicadas

### Scraping Gen√©rico
"Este POC usa um parser gen√©rico que tenta identificar licita√ß√µes em qualquer estrutura HTML. Na produ√ß√£o, criar√≠amos parsers espec√≠ficos para cada SRE, aumentando a precis√£o de 40% para 95%+."

### Performance
"Atualmente processa 1 SRE a cada 2 segundos (rate limiting conservador). Podemos otimizar para processar todas as 47 SREs em menos de 2 minutos com paraleliza√ß√£o controlada."

### Dados
"Os campos extra√≠dos s√£o b√°sicos. Com an√°lise detalhada de cada portal, extrairemos: n√∫mero do edital, valor estimado, modalidade, documentos anexos, etc."

## üìä Pr√≥ximos Passos Sugeridos

### Fase 2: An√°lise Detalhada (2 semanas)
- An√°lise manual de 10-15 SREs priorit√°rias
- Documenta√ß√£o de estruturas HTML
- Identifica√ß√£o de padr√µes comuns
- **Entreg√°vel**: Documento t√©cnico com mapeamento

### Fase 3: Parsers Espec√≠ficos (3-4 semanas)
- Desenvolvimento de scrapers otimizados
- Extra√ß√£o de todos os campos relevantes
- Testes de regress√£o
- **Entreg√°vel**: Sistema funcional para SREs priorit√°rias

### Fase 4: Automa√ß√£o Completa (2-3 semanas)
- Agendamento autom√°tico (ex: di√°rio √†s 6h)
- Sistema de alertas por email
- Dashboard administrativo
- **Entreg√°vel**: Sistema rodando em produ√ß√£o

### Fase 5: Integra√ß√£o (1-2 semanas)
- API para sistemas do cliente
- Webhooks para eventos importantes
- Documenta√ß√£o de integra√ß√£o
- **Entreg√°vel**: API documentada e testada

## üéØ Budget Estimado

### Desenvolvimento
- Fase 2: [definir com cliente]
- Fase 3: [definir com cliente]
- Fase 4: [definir com cliente]
- Fase 5: [definir com cliente]

### Infraestrutura (mensal)
- **Meses 1-3**: R$ 0 (free tier)
- **Meses 4-6**: ~R$ 50-100 (Supabase Pro)
- **Meses 7+**: ~R$ 150-300 (conforme escala)

## ü§î Perguntas Esperadas

### "Por que alguns dados est√£o incompletos?"
"O POC usa scraping gen√©rico. Com parsers espec√≠ficos por SRE, conseguiremos 100% dos campos. Exemplo: de 'objeto vago' para 'Preg√£o 123/2025 - Aquisi√ß√£o de materiais escolares - R$ 50.000,00'."

### "Quanto tempo demora para coletar todas as 47 SREs?"
"Atualmente: ~2 minutos com rate limiting conservador. Otimizado: ~30-40 segundos. Frequ√™ncia recomendada: 1x por dia ou quando houver alertas de novos editais."

### "E se um portal SRE sair do ar?"
"O sistema registra falhas individuais e continua com as outras SREs. Tentativas de retry autom√°tico ap√≥s X horas. Alertas para administradores."

### "Posso integrar com meu sistema atual?"
"Sim! A API REST permite integra√ß√£o com qualquer sistema. Tamb√©m podemos criar webhooks para notifica√ß√µes em tempo real."

## üìû Contato

Para d√∫vidas ou discuss√£o de pr√≥ximos passos:
- **Email**: [seu-email@example.com]
- **Telefone**: [seu-telefone]
- **GitHub**: [seu-usuario/projeto]

---

**Preparado para impressionar! üöÄ**
