# ğŸ“‹ Importador de LicitaÃ§Ãµes e NotÃ­cias - SREs MG# Importador de LicitaÃ§Ãµes - POCThis is a [Next.js](https://nextjs.org) project bootstrapped with [`create-next-app`](https://nextjs.org/docs/app/api-reference/cli/create-next-app).



# ğŸ“‹ Importador de LicitaÃ§Ãµes e NotÃ­cias - SREs MG

Sistema inteligente de coleta, categorizaÃ§Ã£o e anÃ¡lise de **licitaÃ§Ãµes** e **notÃ­cias** das SuperintendÃªncias Regionais de Ensino de Minas Gerais.

---

## ğŸ¯ Funcionalidades

### ğŸ›ï¸ **Sistema de LicitaÃ§Ãµes**
- âœ… Coleta automÃ¡tica de licitaÃ§Ãµes de 47 SREs
- âœ… Parsing especÃ­fico para portais Joomla
- âœ… Dashboard visual com grÃ¡ficos e estatÃ­sticas
- âœ… Filtros avanÃ§ados (SRE, modalidade, situaÃ§Ã£o, valor)
- âœ… PÃ¡gina de detalhes completa por licitaÃ§Ã£o
- âœ… Armazenamento em PostgreSQL (Supabase)

### ğŸ“° **Sistema de NotÃ­cias com IA** (NOVO!)
- ğŸ¤– **CategorizaÃ§Ã£o Inteligente**: 8 categorias automÃ¡ticas
  - LicitaÃ§Ãµes e Compras
  - Processos Seletivos
  - Editais de RH
  - Avisos Administrativos
  - Programas Educacionais
  - Eventos
  - Resultados



---Sistema de coleta automatizada de licitaÃ§Ãµes pÃºblicas das SuperintendÃªncias Regionais de Ensino (SREs) de Minas Gerais.## Getting Started



## ğŸ¯ Funcionalidades



### ğŸ›ï¸ **Sistema de LicitaÃ§Ãµes**## ğŸ¯ Sobre o ProjetoFirst, run the development server:

- âœ… Coleta automÃ¡tica de licitaÃ§Ãµes de 47 SREs

- âœ… Parsing especÃ­fico para portais Joomla

- âœ… Dashboard visual com grÃ¡ficos e estatÃ­sticas

- âœ… Filtros avanÃ§ados (SRE, modalidade, situaÃ§Ã£o, valor)Este Ã© um **Proof of Concept (POC)** que demonstra a viabilidade tÃ©cnica de coletar e centralizar informaÃ§Ãµes sobre licitaÃ§Ãµes pÃºblicas de 47 SREs do estado de Minas Gerais.```bash

- âœ… PÃ¡gina de detalhes completa por licitaÃ§Ã£o

- âœ… Armazenamento em PostgreSQL (Supabase)npm run dev



### ğŸ“° **Sistema de NotÃ­cias com IA** (NOVO!)### Funcionalidades do POC# or

- ğŸ¤– **CategorizaÃ§Ã£o Inteligente**: 8 categorias automÃ¡ticas

  - LicitaÃ§Ãµes e Comprasyarn dev

  - Processos Seletivos

  - Editais de RH- âœ… Coleta automatizada de dados de portais SRE# or

  - Avisos Administrativos

  - Programas Educacionais- âœ… Armazenamento estruturado em PostgreSQL (Supabase)pnpm dev

  - Eventos

  - Resultados- âœ… Dashboard web para visualizaÃ§Ã£o# or

  - Outros

- âœ… API REST para integraÃ§Ã£obun dev

- ğŸ§  **AnÃ¡lise com IA/NLP Local**:

  - ExtraÃ§Ã£o de entidades (datas, valores, processos, pessoas, instituiÃ§Ãµes)- âœ… Logs de execuÃ§Ã£o e monitoramento```

  - AnÃ¡lise de sentimento (positivo/neutro/negativo)

  - DetecÃ§Ã£o de prioridade (alta/mÃ©dia/baixa)

  - Score de relevÃ¢ncia (0-100)

  - Resumo automÃ¡tico## ğŸ› ï¸ Stack TecnolÃ³gicoOpen [http://localhost:3000](http://localhost:3000) with your browser to see the result.

  - Palavras-chave extraÃ­das

  - AÃ§Ãµes recomendadas



- ğŸ“Š **Dashboard Visual**:- **Frontend/Backend**: Next.js 15 (App Router) + TypeScriptYou can start editing the page by modifying `app/page.tsx`. The page auto-updates as you edit the file.

  - 4 cards de estatÃ­sticas

  - 2 grÃ¡ficos interativos (categorias + SREs)- **Database**: PostgreSQL via Supabase

  - Busca full-text em portuguÃªs

  - Filtros por categoria, prioridade e SRE- **Web Scraping**: Cheerio + AxiosThis project uses [`next/font`](https://nextjs.org/docs/app/building-your-application/optimizing/fonts) to automatically optimize and load [Geist](https://vercel.com/font), a new font family for Vercel.

  - Lista de notÃ­cias com badges e tags

  - OrdenaÃ§Ã£o por relevÃ¢ncia/data/prioridade- **Styling**: Tailwind CSS



- ğŸ” **PÃ¡gina de Detalhes**:- **Deploy**: Vercel (recomendado)## Learn More

  - Resumo inteligente gerado por IA

  - ConteÃºdo completo formatado

  - AÃ§Ãµes recomendadas personalizadas

  - Entidades extraÃ­das organizadas## ğŸ“‹ PrÃ©-requisitosTo learn more about Next.js, take a look at the following resources:

  - Palavras-chave e tags

  - Documentos anexos (PDFs, Google Drive)

  - Links relacionados

- Node.js 18+ e npm- [Next.js Documentation](https://nextjs.org/docs) - learn about Next.js features and API.

---

- Conta no Supabase (gratuita)- [Learn Next.js](https://nextjs.org/learn) - an interactive Next.js tutorial.

## ğŸš€ InÃ­cio RÃ¡pido

- Git (opcional)

### **1. InstalaÃ§Ã£o**

You can check out [the Next.js GitHub repository](https://github.com/vercel/next.js) - your feedback and contributions are welcome!

```bash

# Clone o repositÃ³rio## ğŸš€ ConfiguraÃ§Ã£o RÃ¡pida

git clone <seu-repositorio>

cd Importadordelicitacoes## Deploy on Vercel



# Instale dependÃªncias### 1. Instalar DependÃªncias

npm install

The easiest way to deploy your Next.js app is to use the [Vercel Platform](https://vercel.com/new?utm_medium=default-template&filter=next.js&utm_source=create-next-app&utm_campaign=create-next-app-readme) from the creators of Next.js.

# Configure variÃ¡veis de ambiente

copy .env.example .env.local```bash

# Edite .env.local com suas credenciais do Supabase

```npm installCheck out our [Next.js deployment documentation](https://nextjs.org/docs/app/building-your-application/deploying) for more details.



### **2. Configure o Supabase**```



1. Acesse [supabase.com](https://supabase.com/dashboard)### 2. Configurar Supabase

2. Crie um novo projeto (ou use existente)

3. VÃ¡ em **SQL Editor** â†’ **New Query**1. Crie uma conta gratuita em [supabase.com](https://supabase.com)

4. Execute os schemas:2. Crie um novo projeto

   - `lib/supabase/schema-licitacoes.sql` (licitaÃ§Ãµes)3. VÃ¡ em **Project Settings > API** e copie:

   - `lib/supabase/schema-noticias.sql` (notÃ­cias)   - Project URL

   - anon/public key

### **3. Inicie o Servidor**   - service_role key (Settings > API > service_role)



```bash### 3. Configurar VariÃ¡veis de Ambiente

npm run dev

# Acesse: http://localhost:3001Renomeie `.env.local.example` para `.env.local` e preencha:

```

```env

### **4. Valide o Sistema**NEXT_PUBLIC_SUPABASE_URL=https://seu-projeto.supabase.co

NEXT_PUBLIC_SUPABASE_ANON_KEY=sua-chave-anon

```powershellSUPABASE_SERVICE_ROLE_KEY=sua-chave-service-role

# Execute o script de validaÃ§Ã£o```

.\validar-sistema.ps1

```### 4. Criar Tabelas no Supabase



### **5. Colete Dados**1. No Supabase, acesse **SQL Editor**

2. Copie todo o conteÃºdo de `lib/supabase/schema.sql`

```powershell3. Cole no editor e execute (**Run**)

# Coletar licitaÃ§Ãµes (3 SREs)

curl "http://localhost:3001/api/scrape-specific?count=3"Isso criarÃ¡:

- Tabela `licitacoes` (dados coletados)

# Coletar notÃ­cias com IA (1 SRE)- Tabela `scraping_logs` (histÃ³rico de execuÃ§Ãµes)

curl "http://localhost:3001/api/scrape-news?sre=barbacena&pages=2"- Ãndices para performance

```- Policies RLS bÃ¡sicas



### **6. Acesse os Dashboards**### 5. Executar o Projeto



- **LicitaÃ§Ãµes**: http://localhost:3001/dashboard```bash

- **NotÃ­cias**: http://localhost:3001/noticiasnpm run dev

```

---

Acesse: http://localhost:3001

## ğŸ“ Estrutura do Projeto

## ğŸ¤– Scripts de AutomaÃ§Ã£o

```

Importadordelicitacoes/Este projeto inclui **scripts PowerShell** para automatizar tarefas comuns:

â”œâ”€â”€ app/

â”‚   â”œâ”€â”€ api/### ğŸš€ Setup Automatizado

â”‚   â”‚   â”œâ”€â”€ licitacoes/          # APIs de licitaÃ§Ãµes```powershell

â”‚   â”‚   â”œâ”€â”€ noticias/            # APIs de notÃ­cias.\setup.ps1

â”‚   â”‚   â”œâ”€â”€ scrape-specific/     # Coleta de licitaÃ§Ãµes```

â”‚   â”‚   â””â”€â”€ scrape-news/         # Coleta de notÃ­ciasConfigura todo o projeto automaticamente.

â”‚   â”œâ”€â”€ dashboard/               # Dashboard de licitaÃ§Ãµes

â”‚   â”œâ”€â”€ noticias/                # Dashboard de notÃ­cias### ğŸ¬ Demo Automatizada

â”‚   â”‚   â””â”€â”€ [id]/                # Detalhes de notÃ­cia```powershell

â”‚   â””â”€â”€ page.tsx                 # Redireciona para /dashboard.\demo.ps1

â”œâ”€â”€ lib/```

â”‚   â”œâ”€â”€ scrapers/Executa demo completa: inicia servidor, testa API, coleta dados, abre navegador.

â”‚   â”‚   â”œâ”€â”€ specific-parser.ts   # Parser de licitaÃ§Ãµes

â”‚   â”‚   â””â”€â”€ news-parser.ts       # Parser de notÃ­cias (NOVO)### ğŸ” VerificaÃ§Ã£o do Sistema

â”‚   â”œâ”€â”€ ai/```powershell

â”‚   â”‚   â””â”€â”€ categorizer.ts       # Categorizador IA/NLP (NOVO).\check.ps1

â”‚   â””â”€â”€ supabase/```

â”‚       â”œâ”€â”€ client.ts            # Cliente SupabaseVerifica se tudo estÃ¡ configurado corretamente.

â”‚       â”œâ”€â”€ queries.ts           # Queries do banco

â”‚       â”œâ”€â”€ schema-licitacoes.sql### ğŸ” Coleta Automatizada

â”‚       â””â”€â”€ schema-noticias.sql  # Schema notÃ­cias (NOVO)```powershell

â”œâ”€â”€ SREs.txt                     # Lista de 47 SREs# Coletar 3 SREs

â”œâ”€â”€ .env.example                 # Exemplo de configuraÃ§Ã£o.\scrape.ps1

â”œâ”€â”€ validar-sistema.ps1          # Script de validaÃ§Ã£o (NOVO)

â””â”€â”€ DOCUMENTACAO/# Coletar 5 SREs

    â”œâ”€â”€ INICIO-RAPIDO-NOTICIAS.md.\scrape.ps1 -Count 5

    â”œâ”€â”€ COMO-TESTAR-NOTICIAS.md

    â”œâ”€â”€ SISTEMA-NOTICIAS-IA.md# SRE especÃ­fica

    â””â”€â”€ RESPOSTA-SISTEMA-IA.md.\scrape.ps1 -SRE "metropa"

``````



---ğŸ“š **DocumentaÃ§Ã£o completa**: Ver `SCRIPTS.md`



## ğŸ› ï¸ Tecnologias## ğŸ“– Como Usar o POC



- **Framework**: Next.js 15.5.4 (App Router)### Interface Web

- **Runtime**: Node.js

- **Database**: PostgreSQL (Supabase)1. **PÃ¡gina Inicial** (/)

- **UI**: React + Tailwind CSS   - VisÃ£o geral do sistema

- **Charts**: Recharts   - Acesso ao Dashboard e Coleta

- **Icons**: Lucide React

- **Scraping**: Cheerio + Axios2. **Coletar Dados** (/scrape)

- **IA/NLP**: ImplementaÃ§Ã£o local (sem APIs externas)   - Escolha quantas SREs coletar (1-47)

   - Clique em "Iniciar Coleta"

---   - Aguarde o processamento (2s por SRE)

   - Visualize resultados em tempo real

## ğŸ“Š Dados Coletados

3. **Dashboard** (/dashboard)

### LicitaÃ§Ãµes (18 campos):   - Visualize licitaÃ§Ãµes coletadas

- NÃºmero do edital   - EstatÃ­sticas gerais

- Modalidade   - Filtros por SRE

- Objeto

- Valor estimado### API Endpoints

- Data de publicaÃ§Ã£o

- Data de abertura#### GET /api/scrape

- SituaÃ§Ã£oInicia coleta de dados

- Categoria

- SRE origem```bash

# Coletar primeiras 3 SREs

### NotÃ­cias (30+ campos):curl http://localhost:3001/api/scrape?count=3

- TÃ­tulo, conteÃºdo, resumo

- Categoria IA (8 tipos)# Coletar SRE especÃ­fica

- Subcategoria IAcurl http://localhost:3001/api/scrape?sre=metropa

- Tags automÃ¡ticas```

- Entidades extraÃ­das (datas, valores, processos, pessoas, instituiÃ§Ãµes, locais)

- Sentimento (positivo/neutro/negativo)#### GET /api/licitacoes

- Prioridade (alta/mÃ©dia/baixa)Lista licitaÃ§Ãµes coletadas

- Score de relevÃ¢ncia (0-100)

- Resumo IA```bash

- Palavras-chave IA# Todas as licitaÃ§Ãµes

- AÃ§Ãµes recomendadascurl http://localhost:3001/api/licitacoes

- Documentos anexos

- Links externos# Por SRE especÃ­fica

curl http://localhost:3001/api/licitacoes?sre=SRE+metropa

---```



## ğŸ§ª Testes#### GET /api/logs

HistÃ³rico de coletas

### LicitaÃ§Ãµes:

```powershell```bash

# Teste rÃ¡pido (3 SREs)curl http://localhost:3001/api/logs

curl "http://localhost:3001/api/scrape-specific?count=3"```



# Coleta completa (47 SREs)## ğŸ” Arquitetura do POC

curl "http://localhost:3001/api/scrape-specific?count=47"

``````

/app

### NotÃ­cias:  /api

```powershell    /scrape       â†’ Endpoint de coleta

# Teste rÃ¡pido (1 SRE)    /licitacoes   â†’ Consulta de dados

curl "http://localhost:3001/api/scrape-news?sre=barbacena&pages=2"    /logs         â†’ Logs de execuÃ§Ã£o

  /dashboard      â†’ Interface de visualizaÃ§Ã£o

# MÃºltiplas SREs  /scrape         â†’ Interface de coleta

curl "http://localhost:3001/api/scrape-news?count=5&pages=1"  page.tsx        â†’ Homepage



# SREs especÃ­ficas (POST)/lib

curl -X POST "http://localhost:3001/api/scrape-news" `  /scrapers

  -H "Content-Type: application/json" `    sre-scraper.ts â†’ LÃ³gica de web scraping

  -d '{\"sres\": [\"barbacena\", \"uba\"], \"pages\": 2}'    sre-urls.ts    â†’ Lista de 47 SREs

```  /supabase

    client.ts      â†’ Cliente Supabase

### ValidaÃ§Ã£o Completa:    queries.ts     â†’ OperaÃ§Ãµes de banco

```powershell    schema.sql     â†’ Schema do banco

.\validar-sistema.ps1

```SREs.txt          â†’ URLs originais

```

---

## âš ï¸ LimitaÃ§Ãµes do POC

## ğŸ“š DocumentaÃ§Ã£o

Este Ã© um **Proof of Concept** com limitaÃ§Ãµes intencionais:

### Guias de InÃ­cio:

- **[InÃ­cio RÃ¡pido - NotÃ­cias](INICIO-RAPIDO-NOTICIAS.md)** - 3 passos para comeÃ§ar1. **Scraping GenÃ©rico**: 

- **[Como Testar - NotÃ­cias](COMO-TESTAR-NOTICIAS.md)** - 10 testes completos   - Parser bÃ¡sico que funciona melhor com alguns portais

   - Cada SRE pode ter estrutura HTML diferente

### Arquitetura:   - ProduÃ§Ã£o requer parsers especÃ­ficos por SRE

- **[Sistema de NotÃ­cias IA](SISTEMA-NOTICIAS-IA.md)** - DocumentaÃ§Ã£o tÃ©cnica completa

- **[Resposta Sistema IA](RESPOSTA-SISTEMA-IA.md)** - ExplicaÃ§Ã£o detalhada2. **Rate Limiting Simples**:

   - Delay fixo de 2s entre requisiÃ§Ãµes

### Scripts:   - NÃ£o hÃ¡ retry automÃ¡tico

- **`test-noticias.ps1`** - Testes automatizados   - Sem controle de concorrÃªncia

- **`validar-sistema.ps1`** - ValidaÃ§Ã£o do setup

3. **ValidaÃ§Ã£o MÃ­nima**:

---   - Dados sÃ£o salvos "as-is"

   - Pouca normalizaÃ§Ã£o

## ğŸ”§ Comandos Ãšteis   - Campos opcionais



```bash4. **Sem AutenticaÃ§Ã£o**:

# Desenvolvimento   - Endpoints pÃºblicos

npm run dev              # Inicia servidor (port 3001)   - Sem controle de acesso

npm run build            # Build de produÃ§Ã£o   - Supabase RLS configurado como pÃºblico

npm start                # Inicia servidor de produÃ§Ã£o

## ğŸ¨ Melhorias Sugeridas para ProduÃ§Ã£o

# ValidaÃ§Ã£o

.\validar-sistema.ps1    # Valida configuraÃ§Ã£o completa### Scraping AvanÃ§ado

- [ ] Parser especÃ­fico por SRE apÃ³s anÃ¡lise manual

# Testes- [ ] DetecÃ§Ã£o de mudanÃ§as nos portais

.\test-noticias.ps1      # Testa coleta de notÃ­cias- [ ] OCR para PDFs de editais

```- [ ] Puppeteer para sites com JavaScript



---### Performance

- [ ] Queue system (Bull/BullMQ) para processamento assÃ­ncrono

## ğŸ¨ Capturas de Tela- [ ] Caching com Redis

- [ ] Scraping paralelo controlado

### Dashboard de LicitaÃ§Ãµes- [ ] Incremental updates (apenas novos editais)

- GrÃ¡ficos de barras e pizza

- Filtros avanÃ§ados### Monitoramento

- Lista de licitaÃ§Ãµes clicÃ¡vel- [ ] Alertas de falha via email/Slack

- NavegaÃ§Ã£o para notÃ­cias- [ ] MÃ©tricas de sucesso por SRE

- [ ] Dashboard de saÃºde do sistema

### Dashboard de NotÃ­cias (NOVO!)- [ ] Logs estruturados (Datadog/Sentry)

- 4 cards de estatÃ­sticas

- GrÃ¡fico por categoria (8 tipos)### Dados

- GrÃ¡fico por SRE (Top 10)- [ ] ValidaÃ§Ã£o rigorosa com Zod

- Busca full-text- [ ] NormalizaÃ§Ã£o de datas/valores

- Filtros dinÃ¢micos- [ ] DetecÃ§Ã£o de duplicatas

- Lista com badges de prioridade- [ ] HistÃ³rico de alteraÃ§Ãµes



### Detalhes de NotÃ­cia (NOVO!)### SeguranÃ§a

- Resumo inteligente (IA)- [ ] AutenticaÃ§Ã£o (NextAuth.js)

- Badges de categoria e prioridade- [ ] API Keys para endpoints

- Score de relevÃ¢ncia- [ ] RLS policies adequadas

- Entidades extraÃ­das organizadas- [ ] Rate limiting por usuÃ¡rio

- AÃ§Ãµes recomendadas

- Documentos anexos## ğŸ“Š Estrutura do Banco de Dados

- Links relacionados

### Tabela: licitacoes

---```sql

id                UUID (PK)

## ğŸš€ PrÃ³ximos Passossre_source        VARCHAR(100)   -- Nome da SRE

numero_edital     VARCHAR(50)    -- NÃºmero do edital

### Curto Prazo:modalidade        VARCHAR(50)    -- PregÃ£o, ConcorrÃªncia, etc.

- [ ] Coleta automÃ¡tica diÃ¡ria (cron jobs)objeto            TEXT           -- DescriÃ§Ã£o

- [ ] Sistema de alertas por emailvalor_estimado    DECIMAL        -- Valor em R$

- [ ] ExportaÃ§Ã£o de relatÃ³rios (PDF/Excel)data_publicacao   DATE

- [ ] Busca avanÃ§ada com filtros combinadosdata_abertura     TIMESTAMP

situacao          VARCHAR(50)    -- Aberto, Encerrado, etc.

### MÃ©dio Prazo:documentos        JSONB          -- URLs de documentos

- [ ] Dashboard unificado (licitaÃ§Ãµes + notÃ­cias)raw_data          JSONB          -- Dados brutos coletados

- [ ] AnÃ¡lise de tendÃªncias temporaiscreated_at        TIMESTAMP

- [ ] ComparaÃ§Ã£o entre SREsupdated_at        TIMESTAMP

- [ ] API pÃºblica REST```



### Longo Prazo:### Tabela: scraping_logs

- [ ] Machine Learning para previsÃµes```sql

- [ ] IntegraÃ§Ã£o com outros sistemasid              UUID (PK)

- [ ] Mobile app (React Native)sre_source      VARCHAR(100)

- [ ] Sistema de notificaÃ§Ãµes pushstatus          VARCHAR(50)     -- success, error, in_progress

records_found   INTEGER

---error_message   TEXT

started_at      TIMESTAMP

## ğŸ› Troubleshootingcompleted_at    TIMESTAMP

```

### Erro: "Connection refused"

**SoluÃ§Ã£o:** Inicie o servidor com `npm run dev`## ğŸ› Troubleshooting



### Erro: "Table does not exist"### Erro: "Missing Supabase environment variables"

**SoluÃ§Ã£o:** Execute os schemas SQL no Supabase- Verifique se `.env.local` existe e estÃ¡ preenchido

- Reinicie o servidor (`npm run dev`)

### Dashboard vazio

**SoluÃ§Ã£o:** Execute coleta de dados primeiro### Nenhuma licitaÃ§Ã£o coletada

- Portais SRE podem estar offline

### Erro de autenticaÃ§Ã£o- HTML pode ter mudado (parser genÃ©rico)

**SoluÃ§Ã£o:** Verifique credenciais em `.env.local`- Confira logs em `/api/logs`



**DocumentaÃ§Ã£o completa:** `COMO-TESTAR-NOTICIAS.md`### Erro de conexÃ£o com Supabase

- Verifique credenciais em `.env.local`

---- Confirme que schema SQL foi executado

- Teste conexÃ£o no Supabase Dashboard

## ğŸ“Š EstatÃ­sticas do Projeto

## ğŸ“ Lista de SREs

- **Linhas de cÃ³digo**: ~8.000+

- **APIs**: 8 endpointsO sistema monitora 47 SREs:

- **Dashboards**: 3 (home, licitaÃ§Ãµes, notÃ­cias)- Metropolitana A, B, C

- **PÃ¡ginas**: 5+ (incluindo detalhes)- Almenara, AraÃ§uaÃ­, Barbacena, Belo Horizonte

- **Componentes**: 15+- Carangola, Caratinga, Caxambu, Conselheiro Lafaiete

- **SREs cobertas**: 47- E mais 37...

- **Categorias IA**: 8

- **Tipos de entidades**: 6Ver lista completa em `lib/scrapers/sre-urls.ts` ou `SREs.txt`.



---## ğŸ¤ ApresentaÃ§Ã£o para Cliente



## ğŸ“ LicenÃ§a### Pontos-Chave



Este projeto foi desenvolvido para fins educacionais e administrativos, focado na coleta e anÃ¡lise de dados pÃºblicos das SREs de Minas Gerais.1. **Viabilidade TÃ©cnica**: âœ… POC demonstra que Ã© possÃ­vel coletar dados

2. **Escalabilidade**: Sistema preparado para crescer (Next.js + Supabase)

---3. **Manutenibilidade**: CÃ³digo TypeScript, bem estruturado

4. **Custo-benefÃ­cio**: Stack gratuita no inÃ­cio (Vercel + Supabase free tier)

## ğŸ¤ Contribuindo

### Demo Script

ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para:

- Reportar bugs1. Mostrar homepage explicando conceito

- Sugerir novas funcionalidades2. Executar coleta de 2-3 SREs na pÃ¡gina /scrape

- Melhorar a documentaÃ§Ã£o3. Visualizar resultados no dashboard

- Enviar pull requests4. Mostrar API endpoints funcionando

5. Apresentar cÃ³digo limpo e documentado

---

### PrÃ³ximos Passos Sugeridos

## ğŸ“§ Contato

1. **Fase 2**: AnÃ¡lise detalhada de 5-10 SREs prioritÃ¡rias

Para dÃºvidas ou sugestÃµes, abra uma issue no repositÃ³rio.2. **Fase 3**: Parsers especÃ­ficos para SREs analisadas

3. **Fase 4**: Sistema de alertas e notificaÃ§Ãµes

---4. **Fase 5**: IntegraÃ§Ã£o com sistemas do cliente



**Desenvolvido com â¤ï¸ para facilitar o acesso a informaÃ§Ãµes pÃºblicas das SREs de Minas Gerais**---

## ğŸ¤– IntegraÃ§Ã£o OpenRouter (IA AvanÃ§ada)

### O Que Ã‰?

Sistema hÃ­brido de categorizaÃ§Ã£o usando **LLMs reais** (GPT-4, Claude, Gemini) via OpenRouter com fallback para NLP local.

### Recursos:
- âœ… **+100 modelos LLM** disponÃ­veis
- âœ… **Cache automÃ¡tico** (economia 30-50%)
- âœ… **Fallback inteligente** (3 nÃ­veis: OpenRouter â†’ Cache â†’ NLP Local)
- âœ… **Tracking completo** (custos, tokens, performance)
- âœ… **SincronizaÃ§Ã£o automÃ¡tica** via SQL triggers

### Custo:
- ğŸ’° **GPT-4o Mini** (recomendado): $0.38 / 1.000 notÃ­cias
- ğŸ’° **Claude 3 Haiku**: $0.61 / 1.000 notÃ­cias
- ğŸ’° **Llama 3.1 70B**: $0.57 / 1.000 notÃ­cias

### Quick Start:
```bash
# 1. Executar schema SQL no Supabase
lib/supabase/schema-openrouter.sql

# 2. Configurar .env.local
OPENROUTER_API_KEY=sk-or-v1-sua-chave
OPENROUTER_DEFAULT_MODEL=openai/gpt-4o-mini
OPENROUTER_FALLBACK_TO_LOCAL=true

# 3. Adicionar crÃ©ditos ($5-10)
https://openrouter.ai/credits

# 4. Testar
curl "http://localhost:3001/api/scrape-news?sre=barbacena&pages=1"
```

### DocumentaÃ§Ã£o Completa:
- ğŸ“š **Quick Start**: `docs/QUICK-START-OPENROUTER.md`
- ğŸ“Š **Custos e Modelos**: `docs/OPENROUTER-CUSTOS.md`
- ğŸ“‹ **Resumo**: `docs/RESUMO-INTEGRACAO-OPENROUTER.md`

---

## ğŸ“„ LicenÃ§a



---Este Ã© um projeto de demonstraÃ§Ã£o (POC). Direitos e licenÃ§a a definir com o cliente.



## âœ… Status do Projeto## ğŸ‘¨â€ğŸ’» Suporte



- âœ… Sistema de LicitaÃ§Ãµes: **100% Operacional**Para dÃºvidas sobre este POC, consulte:

- âœ… Sistema de NotÃ­cias com IA: **100% Operacional**- DocumentaÃ§Ã£o do Next.js: https://nextjs.org/docs

- âœ… Dashboards Visuais: **100% Operacional**- DocumentaÃ§Ã£o do Supabase: https://supabase.com/docs

- âœ… DocumentaÃ§Ã£o: **Completa**- `.github/copilot-instructions.md` para contexto tÃ©cnico

- ğŸ”„ Testes em ProduÃ§Ã£o: **Em Andamento**

---

**Ãšltima atualizaÃ§Ã£o**: 1 de outubro de 2025

**VersÃ£o**: 1.0.0 (POC)  
**Data**: Outubro 2025
